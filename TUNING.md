# Model Tuning & Self-Play Training

This document outlines methods for improving our RL bot with the following additions:
- RL adjustments:
    - Experience Replay
    - Double Deep Q Network (DDQN)
- Model Tuning:
    - Neural network architecture tuning (layers, nodes)
    - Parameters: learning rate, gamma, epsilon
- Self-play Training Regiment: 'best' opponent setup

# RL Adjustments
## Experience Replay
- Memory size: trying to find a logical number to use. 
    - In our training, game lengths average 10-15 moves.
    - Let's train for ~100 games (1000-1500 moves in memory)
## Double Deep Q Network (DDQN)


# Model Tuning
## Neural network architecture tuning (layers, nodes)
## Parameters: learning rate, gamma, epsilon


# Self-play Training Regiment: 'best' opponent setup